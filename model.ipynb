{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "file_path = \"fake reviews dataset.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: \n",
      "             category  rating label  \\\n",
      "0  Home_and_Kitchen_5       5    CG   \n",
      "1  Home_and_Kitchen_5       5    CG   \n",
      "2  Home_and_Kitchen_5       5    CG   \n",
      "3  Home_and_Kitchen_5       1    CG   \n",
      "4  Home_and_Kitchen_5       5    CG   \n",
      "\n",
      "                                               text_  \n",
      "0  Love this!  Well made, sturdy, and very comfor...  \n",
      "1  love it, a great upgrade from the original.  I...  \n",
      "2  This pillow saved my back. I love the look and...  \n",
      "3  Missing information on how to use it, but it i...  \n",
      "4  Very nice set. Good quality. We have had the s...  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of dataset\n",
    "\n",
    "print(\"Original dataset: \")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed Dataset:\n",
      "             category  rating label  \\\n",
      "0  Home_and_Kitchen_5       5    CG   \n",
      "1  Home_and_Kitchen_5       5    CG   \n",
      "2  Home_and_Kitchen_5       5    CG   \n",
      "3  Home_and_Kitchen_5       1    CG   \n",
      "4  Home_and_Kitchen_5       5    CG   \n",
      "\n",
      "                                               text_  \n",
      "0  love this well made sturdy and very comfortabl...  \n",
      "1  love it a great upgrade from the original ive ...  \n",
      "2  this pillow saved my back i love the look and ...  \n",
      "3  missing information on how to use it but it is...  \n",
      "4  very nice set good quality we have had the set...  \n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters, numbers and punctuation\n",
    "    text = re.sub(r'[^a-zA-Z\\s]','',text)\n",
    "\n",
    "    #Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+',' ',text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply the preprocessing function to the 'review' column\n",
    "df['text_'] = df['text_'].apply(preprocess_text)\n",
    "\n",
    "print(\"\\nPreprocessed Dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map labels to numerical values\n",
    "label_mapping = {'OR':0, 'CG': 1}\n",
    "df['label'] = df['label'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labeled Dataset:\n",
      "             category  rating  label  \\\n",
      "0  Home_and_Kitchen_5       5      1   \n",
      "1  Home_and_Kitchen_5       5      1   \n",
      "2  Home_and_Kitchen_5       5      1   \n",
      "3  Home_and_Kitchen_5       1      1   \n",
      "4  Home_and_Kitchen_5       5      1   \n",
      "\n",
      "                                               text_  \n",
      "0  love this well made sturdy and very comfortabl...  \n",
      "1  love it a great upgrade from the original ive ...  \n",
      "2  this pillow saved my back i love the look and ...  \n",
      "3  missing information on how to use it but it is...  \n",
      "4  very nice set good quality we have had the set...  \n"
     ]
    }
   ],
   "source": [
    "# Display the labeled dataset\n",
    "print(\"\\nLabeled Dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    df['text_'], df['label'], test_size = 0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Matrix Shape - Training set: (32345, 5000)\n",
      "TF-IDF Matrix Shape - Testing set: (8087, 5000)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "train_features = tfidf_vectorizer.fit_transform(train_data)\n",
    "test_features = tfidf_vectorizer.transform(test_data)\n",
    "\n",
    "#Display the shape of the TF-IDF matrices\n",
    "print(\"\\nTF-IDF Matrix Shape - Training set:\", train_features.shape)\n",
    "print(\"TF-IDF Matrix Shape - Testing set:\", test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation:\n",
      "Accuracy: 0.9028069741560529\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90      4071\n",
      "           1       0.90      0.90      0.90      4016\n",
      "\n",
      "    accuracy                           0.90      8087\n",
      "   macro avg       0.90      0.90      0.90      8087\n",
      "weighted avg       0.90      0.90      0.90      8087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model selection and Training\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(train_features,train_labels)\n",
    "\n",
    "# Predictions on the test set\n",
    "predictions = svm_model.predict(test_features)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "report = classification_report(test_labels,predictions)\n",
    "\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of XGB:  0.8832694447879312\n",
      "classification_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      4071\n",
      "           1       0.89      0.87      0.88      4016\n",
      "\n",
      "    accuracy                           0.88      8087\n",
      "   macro avg       0.88      0.88      0.88      8087\n",
      "weighted avg       0.88      0.88      0.88      8087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "xgb_model.fit(train_features, train_labels)\n",
    "\n",
    "predictions = xgb_model.predict(test_features)\n",
    "\n",
    "accuracy = accuracy_score(test_labels,predictions)\n",
    "report = classification_report(test_labels,predictions)\n",
    "\n",
    "print(\"accuracy of XGB: \", accuracy)\n",
    "print(\"classification_report: \", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of ensemble:  0.9103499443551378\n",
      "classification_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      4071\n",
      "           1       0.91      0.91      0.91      4016\n",
      "\n",
      "    accuracy                           0.91      8087\n",
      "   macro avg       0.91      0.91      0.91      8087\n",
      "weighted avg       0.91      0.91      0.91      8087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "xgb_model = XGBClassifier(random_state = 42)\n",
    "\n",
    "estimators = [('svm',svm_model), ('xgb', xgb_model)]\n",
    "stacking_model = StackingClassifier(estimators=estimators, final_estimator=XGBClassifier())\n",
    "\n",
    "stacking_model.fit(train_features, train_labels)\n",
    "\n",
    "predictions = stacking_model.predict(test_features)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "report  = classification_report(test_labels, predictions)\n",
    "\n",
    "print(\"accuracy of ensemble: \", accuracy)\n",
    "print(\"classification_report: \", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving model\n",
    "\n",
    "import joblib\n",
    "\n",
    "# save model to file\n",
    "joblib.dump(svm_model,'model.pkl')\n",
    "\n",
    "# Save TF-IDF vectorizer to file\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
